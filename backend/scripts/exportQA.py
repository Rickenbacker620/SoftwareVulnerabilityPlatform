from base import *
import csv
import spacy

nlp = spacy.load("en_core_web_sm")

question_dict = {
    "consequence": "What is its consequence",
    "version": "What is its version",
    "attacker": "Who are its attackers",
    "operation": "What is its operation",
    "situation": "What is its situation",
    "location": "What is its location"
}

class DatasetQA(Dataset):
    def __init__(self, dataset) -> None:
        super().__init__(dataset)


    def get_each_part(part, question):
        question = question + "?"
        selected_ann = None

        for ann in other_annotations:
            if ann["part"] == part:
                selected_ann = ann

        if selected_ann == None:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_v": "",
                "text_n": "",
                "is_impossible": False,
                "answer_start": -1
            }

        description = dataset["description"]
        start = selected_ann["start_offset"]
        end = selected_ann["end_offset"]
        text = description[start:end].strip(',. ')

        doc = nlp(text)
        if (doc[0].pos_ == "VERB"):
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": "",
                "text_v": text,
                "is_impossible": True,
                "answer_start": start
            }
        else:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": text,
                "text_v": "",
                "is_impossible": True,
                "answer_start": start
            }




# def exportQA(dataset: DatasetQA):

#         cause_annotations = dataset["cause"]
#         other_annotations = [dataset[cat] for cat in dataset._categories if cat != "cause"]
#         other_annotations = [ann for ann_list in other_annotations for ann in ann_list]

#         caused_by = ""
#         if cause_annotations != []:
#             detail = ""
#             for annotation in cause_annotations:
#                 detail = annotation.get("detail")
#                 caused_by = f"The vulnerability is caused by {detail}. "



        # question_list = [get_each_part(part,question)
        #                     for part,question in question_dict.items()]

        # for q in question_list:
        #     result_upper = {
        #         "id": index,
        #         "cve": dataset["_id"],
        #         "type": dataset["cwe_id"],
        #         "context": dataset["description"]
        #     }
        #     q_final = q | result_upper
        #     writer.writerow(q_final)
        #     index += 1



# file = open("outputs/QA.csv", "w")
# writer = csv.DictWriter(file, fieldnames=[
#                 "cve", "type", "context", "caused_by", "question","text_n","text_v", "is_impossible", "answer_start"])
# writer.writeheader()

def exportQA():

    def get_each_part(part, question):
        question = question + "?"
        selected_ann = None

        for ann in other_annotations:
            if ann["part"] == part:
                selected_ann = ann

        if selected_ann == None:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_v": "",
                "text_n": "",
                "is_impossible": False,
                "answer_start": -1
            }

        description = dataset["description"]
        start = selected_ann["start_offset"]
        end = selected_ann["end_offset"]
        text = description[start:end].strip(',. ')

        doc = nlp(text)
        if (doc[0].pos_ == "VERB"):
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": "",
                "text_v": text,
                "is_impossible": True,
                "answer_start": start
            }
        else:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": text,
                "text_v": "",
                "is_impossible": True,
                "answer_start": start
            }

    index = 1
    with open("QA.csv", "w") as file:
        writer = csv.DictWriter(file, fieldnames=[
                       "id", "cve", "type", "context", "caused_by", "question","text_n","text_v", "is_impossible", "answer_start"])
        writer.writeheader()


        for dataset in approved_datasets:
            annotations = dataset["annotation"]["annotations"]
            cause_annotations = [
                annotation for annotation in annotations if annotation.get("part") == "cause"]
            other_annotations = [
                annotation for annotation in annotations if annotation.get("part") != "cause"]

            question_part1 = ""
            if annotations != []:
                detail = ""
                for annotation in cause_annotations:
                    detail = annotation.get("detail")
                    question_part1 = f"The vulnerability is caused by {detail}. "


            question_dict = {
                "consequence": "What is its consequence",
                "version": "What is its version",
                "attacker": "Who are its attackers",
                "operation": "What is its operation",
                "situation": "What is its situation",
                "location": "What is its location"
            }

            question_list = [get_each_part(part,question)
                             for part,question in question_dict.items()]

            for q in question_list:
                result_upper = {
                    "id": index,
                    "cve": dataset["_id"],
                    "type": dataset["cwe_id"],
                    "context": dataset["description"]
                }
                q_final = q | result_upper
                writer.writerow(q_final)
                index += 1

def get_text(self, start, end, description):
    return description[start, end]

def relocate_text(self, full_description:str, part_description:str):
    text = self.get_text(full_description)
    start = part_description.find(text)
    if start == -1:
        return None, None
    end = start + len(text)
    return start, end

def find_matched_annotations(description, sentence, annotations):
    start = description.find(sentence)
    end = start + len(sentence)
    new_annotations = []
    for annotation in annotations:
        if annotation["start_offset"] >= start and annotation["end_offset"] <= end:
            annotation["start_offset"] = annotation["start_offset"] - start
            annotation["end_offset"] = annotation["end_offset"] - start
            new_annotations.append(annotation)
    return new_annotations




def split_ds(dataset):
    description = dataset["description"]
    sentences = description.split(". ")
    batched_datasets = []
    for sentence in sentences:
        results = find_matched_annotations(description, sentence, dataset["annotation"]["annotations"])
        cp = dataset.copy()
        cp["annotations"] = results
        cp["description"] = sentence
        batched_datasets.append(cp)
    return batched_datasets


for ds in approved_datasets:
    if ds["_id"] == "CVE-2019-12378":
        res = split_ds(ds)
        print(res)
# split_ds(approved_datasets[1])
# exportQA(DatasetQA(approved_datasets[1]))
# exportQA()

# for datas in approved_datasets:
#     ds = Dataset(datas)
#     sentences = ds.description.split(". ")
#     if len(sentences) > 1:
#         print(ds.cve_id)
#         for sentence in sentences:
#             for ann in ds.annotations:
#                 start, end = ann.relocate_text(ds.description, sentence)
#                 if start and end:
#                     print(start, end)
#                     print(sentence[start:end])
#                     print(sentence)
#         exit(0)