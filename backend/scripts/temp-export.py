import json
from pydantic import Json
from base import *
import csv
import spacy

# nlp = spacy.load("en_core_web_sm")

# file = open("file20220303-new.csv", "w")
# writer = csv.DictWriter(file, fieldnames=["CVE", "CWE", "CWE_NAME","description","cause_v", "cause_n"])
# writer.writeheader()
# for dataset in approved_datasets:
#     temp_dict = {}
#     ds = Dataset(dataset)
#     for index, cause in enumerate(ds["cause"]):
#         doc = nlp(ds.description[cause.start_offset: cause.end_offset])
#         if (doc[0].pos_ == "VERB" or doc[0].text in ["do", "does", "did"]):
#             temp_dict["cause_v"] = ds.description[cause.start_offset: cause.end_offset]
#         else:
#             temp_dict["cause_n"] = ds.description[cause.start_offset: cause.end_offset]

#     temp_dict["CVE"] = ds.cve_id
#     temp_dict["CWE"] = ds.cwe_id
#     temp_dict["CWE_NAME"] = ds.cwe_name
#     temp_dict["description"] = ds.description
#     writer.writerow(temp_dict)


# file = open("file20220304.csv", "w")
# writer = csv.DictWriter(file, fieldnames=["CVE", "CWE", "description","description11","description12", "description21", "description22"])
# writer.writeheader()
# for dataset in approved_datasets:
#     temp_dict = {}
#     ds = Dataset(dataset)
#     annotation_text1 = []
#     annotation_text2 = []
#     for index, annotation in enumerate(ds.annotations):
#         annotation_text1.append(ds.description[annotation.start_offset: annotation.end_offset])
#         if annotation.part not in ["location", "version"]:
#             annotation_text2.append(ds.description[annotation.start_offset: annotation.end_offset])
#     annotation_text11 = ",".join(annotation_text1)
#     annotation_text12 = "\t".join(annotation_text1)
#     annotation_text21 = ",".join(annotation_text2)
#     annotation_text22 = "\t".join(annotation_text2)

#     temp_dict["CVE"] = ds.cve_id
#     temp_dict["CWE"] = ds.cwe_id
#     temp_dict["description"] = ds.description
#     temp_dict["description11"] = annotation_text11
#     temp_dict["description12"] = annotation_text12
#     temp_dict["description21"] = annotation_text21
#     temp_dict["description22"] = annotation_text22
#     writer.writerow(temp_dict)

# file = open("file20220306.jsonl", "w")
# for dataset in approved_datasets:

#     ds = Dataset(dataset)
#     splt = ds.description.split(". ")
#     idx = 0
#     for sentence in splt:

#         temp_dict = {}
#         temp_dict["CVE"] = ds.cve_id
#         temp_dict["description"] = sentence
#         temp_dict["annotations"] = []

#         start = ds.description.find(sentence)
#         end = start + len(sentence)

#         for cause in ds["cause"]:
#             if cause.start_offset >= start and cause.end_offset <= end:
#                 cause.start_offset = cause.start_offset - start
#                 cause.end_offset = cause.end_offset - start
#                 temp_dict["annotations"].append(cause.dict())
#                 if idx > 1:
#                     print(ds.cve_id)
#                     print(sentence[cause.start_offset: cause.end_offset])
#         idx += 1
#         to_write = json.dumps(temp_dict)
#         file.write(to_write + "\n")



# file = open("file20220308-operation-before-situation.jsonl", "w")
# for dataset in approved_datasets:
#     ds = Dataset(dataset)
#     situation = ds["situation"]
#     operation = ds["operation"]
#     if situation != [] and operation != []:
#         if situation[0].start_offset > operation[0].end_offset:
#             file.write(ds.cve_id + "\n")


# file = open("file20220308-UNK.jsonl", "w")
# for dataset in approved_datasets:
#     ds = Dataset(dataset)
#     cause = ds["cause"]
#     if cause:
#         detail = None
#         for c in cause:
#             if c.detail:
#                 detail = c.detail

#         for c in cause:
#             if c.detail != detail:
#                 c.detail = detail
#     ds.save_annotations()