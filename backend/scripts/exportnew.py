
from pprint import pprint
import re
from typing import Optional
from pydantic import BaseModel
import httpx
from pymongo import MongoClient
from pymongo.database import Database
from bs4 import BeautifulSoup
import csv
import json
import spacy

nlp = spacy.load("en_core_web_sm")

from pyparsing import restOfLine


def get_database() -> Database:
    CONNECTION_STRING = "mongodb://localhost"
    client = MongoClient(CONNECTION_STRING)
    return client["svp"]


db = get_database()
dataset_collection = db["datasets"]
targets_datasets = dataset_collection.find({"selected": True, "annotation.tags": {
                                           "$all": ["annotated", "approved"], "$nin": ["invalid", "ambiguous"]}})
targets_datasets = list(targets_datasets)
print(len(targets_datasets))


def get_text(self, start, end, description):
    return description[start, end]

def relocate_text(self, full_description:str, part_description:str):
    text = self.get_text(full_description)
    start = part_description.find(text)
    if start == -1:
        return None, None
    end = start + len(text)
    return start, end

def find_matched_annotations(description, sentence, annotations):
    start = description.find(sentence)
    end = start + len(sentence)
    new_annotations = []
    for annotation in annotations:
        if annotation["start_offset"] >= start and annotation["end_offset"] <= end:
            annotation["start_offset"] = annotation["start_offset"] - start
            annotation["end_offset"] = annotation["end_offset"] - start
            new_annotations.append(annotation)
    return new_annotations




def split_ds(dataset):
    description = dataset["description"]
    sentences = description.split(". ")
    batched_datasets = []
    for sentence in sentences:
        results = find_matched_annotations(description, sentence, dataset["annotation"]["annotations"])
        cp = dataset.copy()
        cp["annotations"] = results
        cp["description"] = sentence
        batched_datasets.append(cp)
    return batched_datasets


def exportQA(tgt):

    def get_each_part(part, question):
        question = question + "?"
        selected_ann = None

        for ann in other_annotations:
            if ann["part"] == part:
                selected_ann = ann

        if selected_ann == None:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_v": "",
                "text_n": "",
                "is_impossible": False,
                "answer_start": -1
            }

        description = dataset["description"]
        start = selected_ann["start_offset"]
        end = selected_ann["end_offset"]
        text = description[start:end].strip(',. ')

        doc = nlp(text)
        if (len(doc) != 0 and doc[0].pos_ == "VERB"):
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": "",
                "text_v": text,
                "is_impossible": True,
                "answer_start": start
            }
        else:
            return {
                "caused_by": question_part1,
                "question": question,
                "text_n": text,
                "text_v": "",
                "is_impossible": True,
                "answer_start": start
            }

    index = 1
    with open("QA.csv", "w") as file:
        writer = csv.DictWriter(file, fieldnames=[
                       "id", "cve", "type", "context", "caused_by", "question","text_n","text_v", "is_impossible", "answer_start"])
        writer.writeheader()


        for dataset in tgt:
            annotations = dataset["annotation"]["annotations"]
            cause_annotations = [
                annotation for annotation in annotations if annotation.get("part") == "cause"]
            other_annotations = [
                annotation for annotation in annotations if annotation.get("part") != "cause"]

            question_part1 = ""
            if annotations != []:
                detail = ""
                for annotation in cause_annotations:
                    detail = annotation.get("detail")
                    question_part1 = f"The vulnerability is caused by {detail}. "


            question_dict = {
                "consequence": "What is its consequence",
                "version": "What is its version",
                "attacker": "Who are its attackers",
                "operation": "What is its operation",
                "situation": "What is its situation",
                "location": "What is its location"
            }

            question_list = [get_each_part(part,question)
                             for part,question in question_dict.items()]

            for q in question_list:
                result_upper = {
                    "id": index,
                    "cve": dataset["_id"],
                    "type": dataset["cwe_id"],
                    "context": dataset["description"]
                }
                q_final = q | result_upper
                writer.writerow(q_final)
                index += 1


#  ["TIM", "CON", "INP", "MEM", "LOG", "NUM", "UNK"]
            # obj = {
            #     "id": index,
            #     "cve": dataset["_id"],
            #     "type": dataset["cwe_id"],
            #     "context": dataset["description"],
            #     "question": dataset[""],
            #     "text": dataset[],
            #     "is_impossible": dataset[],
            #     "answer_start: dataset[],
            # }

def exportAnother():
    cat_list = ["TIM", "CON", "INP", "MEM", "LOG", "NUM", "UNK"]
    with open("class.txt", "w") as file:
        for cat in cat_list:
            file.write(cat + "\n")
    with open("dev.txt", "w") as file:
        for dataset in targets_datasets:
            annotations = dataset["annotation"]["annotations"]
            cause_annotations = [
                annotation for annotation in annotations if annotation.get("part") == "cause"]

            detail_cat = ""
            cause_list = []
            for annotation in cause_annotations:
                detail = annotation.get("detail")
                start = annotation.get("start_offset")
                end = annotation.get("end_offset")
                annotation = "hello"
                cause_list.append(dataset["description"][start:end].strip(",. "))
            if cause_list == []:
                continue
            cause_sentence = ",".join(cause_list)
            try:
                idx_num = cat_list.index(detail)
            except Exception as e:
                pass
            # if dataset["_id"] == "CVE-2012-5622":
            #     print(dataset["_id"], cause_sentence, dataset["description"], idx_num)
            finall = ". ".join([cause_sentence.strip(",. "), dataset["description"].strip(",. "), str(idx_num)])
            file.write(finall + "\n")


new_tg = []

for ds in targets_datasets:
    res = split_ds(ds)
    new_tg = new_tg + res

print(len(new_tg))


# exportAnother()
# exportQA(new_tg)


# def exportAnother():
